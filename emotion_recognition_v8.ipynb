{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/DigitalGoldRush/Project-2-Emotional-recognition/blob/main/emotion_recognition_v2.ipynb",
      "authorship_tag": "ABX9TyNzeneOy0HtiOhx3VNYDxnU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DigitalGoldRush/DigitalGoldRush/blob/main/emotion_recognition_v8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "RANDOM_SEED = 123\n"
      ],
      "metadata": {
        "id": "z0elcJHShGG-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Faster way to upload zip files from gdrive to colab\n",
        "# ID of Kaggle emotional dataset\n",
        "! gdown --id 1wrwLq6DqNHLDxU18RYUPY0WcV4ZNG70P"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn0TtaIEEFCE",
        "outputId": "731efc75-c681-493b-9303-db820201f99c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wrwLq6DqNHLDxU18RYUPY0WcV4ZNG70P\n",
            "To: /content/emotional dataset.zip\n",
            "100% 62.6M/62.6M [00:00<00:00, 87.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zip file opener\n",
        "!pip install patool\n",
        "import patoolib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ME1TqApuHMIl",
        "outputId": "8dd70251-b250-4ac9-9232-c8a21bd09eac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting patool\n",
            "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 3.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patoolib.extract_archive('/content/emotional dataset.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "I8AeYeVIHlB2",
        "outputId": "b3a766a8-26b3-49d0-f9f7-5e91ffb2c73b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patool: Extracting /content/emotional dataset.zip ...\n",
            "patool: running /usr/bin/7z x -o./Unpack_3yemu5a4 -- \"/content/emotional dataset.zip\"\n",
            "patool: ... /content/emotional dataset.zip extracted to `emotional dataset' (multiple files in root).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'emotional dataset'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        os.path.join(dirname, filename)"
      ],
      "metadata": {
        "id": "5MeUdG3u3DEP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data preparation\n",
        "train_dir = '/content/emotional dataset/Training/Training'\n",
        "test_dir = '/content/emotional dataset/Testing/Testing'\n",
        "\n",
        "train_angry_dir = '/content/emotional dataset/Training/Training/Angry'\n",
        "train_fear_dir = '/content/emotional dataset/Training/Training/Fear'\n",
        "train_happy_dir = '/content/emotional dataset/Training/Training/Happy'\n",
        "train_neutral_dir = '/content/emotional dataset/Training/Training/Neutral'\n",
        "train_sad_dir = '/content/emotional dataset/Training/Training/Sad'\n",
        "train_surprise_dir = '/content/emotional dataset/Training/Training/Suprise'\n",
        "\n",
        "test_angry_dir = '/content/emotional dataset/Testing/Testing/Angry'\n",
        "test_fear_dir = '/content/emotional dataset/Testing/Testing/Fear'\n",
        "test_happy_dir = '/content/emotional dataset/Testing/Testing/Happy'\n",
        "test_neural_dir = '/content/emotional dataset/Testing/Testing/Neutral'\n",
        "test_sad_dir = '/content/emotional dataset/Testing/Testing/Sad'\n",
        "test_surprise_dir = '/content/emotional dataset/Testing/Testing/Suprise'\n",
        "\n",
        "dir_list = [train_angry_dir, train_fear_dir, train_happy_dir,\n",
        "           train_neutral_dir, train_sad_dir, train_surprise_dir,\n",
        "           test_angry_dir, test_fear_dir, test_happy_dir,\n",
        "           test_neural_dir, test_sad_dir, test_surprise_dir]\n",
        "\n",
        "for d in dir_list:\n",
        "    print(d, len(os.listdir(d)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xkt4CtTI-sWD",
        "outputId": "3b157d37-33af-49ac-8d42-60b6edfeef46"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/emotional dataset/Training/Training/Angry 3995\n",
            "/content/emotional dataset/Training/Training/Fear 4097\n",
            "/content/emotional dataset/Training/Training/Happy 7215\n",
            "/content/emotional dataset/Training/Training/Neutral 4965\n",
            "/content/emotional dataset/Training/Training/Sad 4830\n",
            "/content/emotional dataset/Training/Training/Suprise 3171\n",
            "/content/emotional dataset/Testing/Testing/Angry 958\n",
            "/content/emotional dataset/Testing/Testing/Fear 1024\n",
            "/content/emotional dataset/Testing/Testing/Happy 1774\n",
            "/content/emotional dataset/Testing/Testing/Neutral 1233\n",
            "/content/emotional dataset/Testing/Testing/Sad 1247\n",
            "/content/emotional dataset/Testing/Testing/Suprise 831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# image generator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
        "                                  rotation_range=40,\n",
        "                                  width_shift_range=0.2,\n",
        "                                  height_shift_range=0.2,\n",
        "                                  zoom_range=0.2,\n",
        "                                  horizontal_flip=True,\n",
        "                                  fill_mode='nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                   target_size=(150,150),\n",
        "                                                   batch_size=64,\n",
        "                                                   class_mode='categorical')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(test_dir,\n",
        "                                                             target_size=(150,150),\n",
        "                                                             batch_size=62,\n",
        "                                                             class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2UDHgvbALM0",
        "outputId": "ab1dc035-186d-4e65-d64d-6c7d40e065e3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28273 images belonging to 6 classes.\n",
            "Found 7067 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# callback function\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5,\n",
        "                                                 restore_best_weights=True)"
      ],
      "metadata": {
        "id": "K9SrLVKDm24M"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model = RMS Optimizer, Relu Activation\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2), \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(), \n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'), \n",
        "    tf.keras.layers.Dense(6, activation='softmax')  \n",
        "])\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "model.summary()\n",
        "# keras.utils.plot_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1XDMWPpAec7",
        "outputId": "484d7c05-e804-403f-b961-fd80fbb7171c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 17, 17, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 15, 15, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 7, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3136)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1606144   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 3078      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,669,734\n",
            "Trainable params: 1,669,734\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "\n",
        "fit_model = model.fit(train_generator,\n",
        "                   epochs=10,\n",
        "                   verbose=1,\n",
        "                   validation_data=validation_generator,\n",
        "                   callbacks=early_stopping_cb)\n"
      ],
      "metadata": {
        "id": "-b0QUqnxnZDC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0ca6368-7816-4489-8705-b89034555d5d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "442/442 [==============================] - 145s 327ms/step - loss: 1.6977 - accuracy: 0.2807 - val_loss: 1.6040 - val_accuracy: 0.3433\n",
            "Epoch 2/10\n",
            "442/442 [==============================] - 145s 329ms/step - loss: 1.6369 - accuracy: 0.3224 - val_loss: 1.5007 - val_accuracy: 0.4010\n",
            "Epoch 3/10\n",
            "442/442 [==============================] - 144s 326ms/step - loss: 1.5769 - accuracy: 0.3590 - val_loss: 1.4119 - val_accuracy: 0.4365\n",
            "Epoch 4/10\n",
            "442/442 [==============================] - 143s 324ms/step - loss: 1.5243 - accuracy: 0.3860 - val_loss: 1.3594 - val_accuracy: 0.4643\n",
            "Epoch 5/10\n",
            "442/442 [==============================] - 142s 322ms/step - loss: 1.4777 - accuracy: 0.4054 - val_loss: 1.3437 - val_accuracy: 0.4723\n",
            "Epoch 6/10\n",
            "442/442 [==============================] - 143s 324ms/step - loss: 1.4430 - accuracy: 0.4252 - val_loss: 1.2881 - val_accuracy: 0.4948\n",
            "Epoch 7/10\n",
            "442/442 [==============================] - 144s 325ms/step - loss: 1.4139 - accuracy: 0.4356 - val_loss: 1.2826 - val_accuracy: 0.4967\n",
            "Epoch 8/10\n",
            "442/442 [==============================] - 144s 325ms/step - loss: 1.3889 - accuracy: 0.4492 - val_loss: 1.2516 - val_accuracy: 0.5043\n",
            "Epoch 9/10\n",
            "442/442 [==============================] - 143s 324ms/step - loss: 1.3694 - accuracy: 0.4575 - val_loss: 1.2466 - val_accuracy: 0.5159\n",
            "Epoch 10/10\n",
            "442/442 [==============================] - 143s 324ms/step - loss: 1.3487 - accuracy: 0.4668 - val_loss: 1.2587 - val_accuracy: 0.5086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model loss and accuracy metrics using the evaluate_generator method and the test generator\n",
        "test_loss, test_acc = model.evaluate(validation_generator, verbose=2)\n",
        "\n",
        "# Display the model's loss and accuracy results\n",
        "print(f\"Model Loss: {test_loss}, Model Accuracy: {test_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibAXWSJqx7SK",
        "outputId": "2cdad126-9214-42be-8cfe-08546e62ed5d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "114/114 - 4s - loss: 1.2587 - accuracy: 0.5086 - 4s/epoch - 38ms/step\n",
            "Model Loss: 1.2586877346038818, Model Accuracy: 0.5085608959197998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qVMUXGqX9pNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_adam = ADAM optimizer, Relu **Activation** "
      ],
      "metadata": {
        "id": "BoiT3ilm72Hf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model_adam = ADAM optimizer, Relu Activation function\n",
        "\n",
        "model_adam = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Compile the model\n",
        "model_adam.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_adam.summary()\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mV4hSeKq76XQ",
        "outputId": "f5996f1b-2bae-4a68-c7f1-1a7f2b0fffbc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_16 (Conv2D)          (None, 148, 148, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 74, 74, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 72, 72, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 36, 36, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 34, 34, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 17, 17, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 15, 15, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 3136)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               1606144   \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 6)                 3078      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,669,734\n",
            "Trainable params: 1,669,734\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model_adam\n",
        "\n",
        "model_adam_history = model_adam.fit(train_generator,\n",
        "                   epochs=10,\n",
        "                   verbose=1,\n",
        "                   validation_data=validation_generator,\n",
        "                   callbacks=early_stopping_cb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "Jyin21-183o5",
        "outputId": "68ca7007-6f51-470b-d135-9a67ef64f1c9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 15/442 [>.............................] - ETA: 2:15 - loss: 1.7875 - accuracy: 0.2094"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-1993f7de0034>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                    \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                    callbacks=early_stopping_cb)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model loss and accuracy metrics using the evaluate_generator method and the test generator\n",
        "test_loss, test_acc = model.evaluate(validation_generator, verbose=2)\n",
        "# Evaluate the model_adam loss and accuracy metrics using the evaluate_generator method and the test generator\n",
        "test_loss, test_acc = model_adam.evaluate(validation_generator, verbose=2)\n",
        "\n",
        "# Display the model's loss and accuracy results\n",
        "print(f\"Model_adam Loss: {test_loss}, Model_adam Accuracy: {test_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "Pyw779zq83mo",
        "outputId": "f93bc183-8857-46e8-8836-1fbc17e975a9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-048956b8b6c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate the model_adam loss and accuracy metrics using the evaluate_generator method and the test generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_adam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Display the model's loss and accuracy results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model_adam Loss: {test_loss}, Model_adam Accuracy: {test_acc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'evaluate'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "coYexsKa83jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_swish = RMS Optimizer, Swish **Activation** \n"
      ],
      "metadata": {
        "id": "n6ZNWknj9xgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model_swish = RMS Optimizer, Swish Activation\n",
        "\n",
        "model_swish = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='swish', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='swish'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='swish'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='swish'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='swish'),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "# compile the model_swish\n",
        "model_swish.compile(optimizer=RMSprop(learning_rate=0.001), loss='categorical_crossentropy', metrics = ['accuracy']) \n",
        "model_swish.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGDqA5V283g_",
        "outputId": "94c69234-2fdb-43cd-8a19-8065ef3b4d14"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 148, 148, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 74, 74, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 72, 72, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 36, 36, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 34, 34, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 17, 17, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 15, 15, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 3136)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               1606144   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 6)                 3078      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,669,734\n",
            "Trainable params: 1,669,734\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model_swish\n",
        "model_swish = model_swish.fit(train_generator, epochs=10, verbose=1, validation_data=validation_generator, callbacks=early_stopping_cb)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "818b04gd83dq",
        "outputId": "2c290665-4e8f-4913-cdd4-7e4d35bb18ba"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "442/442 [==============================] - 143s 321ms/step - loss: 1.7608 - accuracy: 0.2557 - val_loss: 1.7021 - val_accuracy: 0.2864\n",
            "Epoch 2/10\n",
            "442/442 [==============================] - 143s 323ms/step - loss: 1.7038 - accuracy: 0.2817 - val_loss: 1.6870 - val_accuracy: 0.2895\n",
            "Epoch 3/10\n",
            "442/442 [==============================] - 143s 323ms/step - loss: 1.6679 - accuracy: 0.3092 - val_loss: 1.5558 - val_accuracy: 0.3607\n",
            "Epoch 4/10\n",
            "442/442 [==============================] - 143s 324ms/step - loss: 1.6318 - accuracy: 0.3334 - val_loss: 1.4964 - val_accuracy: 0.3963\n",
            "Epoch 5/10\n",
            "442/442 [==============================] - 142s 321ms/step - loss: 1.6068 - accuracy: 0.3436 - val_loss: 1.4735 - val_accuracy: 0.4099\n",
            "Epoch 6/10\n",
            "442/442 [==============================] - 142s 320ms/step - loss: 1.5739 - accuracy: 0.3609 - val_loss: 1.4329 - val_accuracy: 0.4348\n",
            "Epoch 7/10\n",
            "442/442 [==============================] - 142s 320ms/step - loss: 1.5478 - accuracy: 0.3751 - val_loss: 1.4122 - val_accuracy: 0.4377\n",
            "Epoch 8/10\n",
            "442/442 [==============================] - 142s 321ms/step - loss: 1.5199 - accuracy: 0.3871 - val_loss: 1.3772 - val_accuracy: 0.4617\n",
            "Epoch 9/10\n",
            "442/442 [==============================] - 142s 321ms/step - loss: 1.4805 - accuracy: 0.4100 - val_loss: 1.3997 - val_accuracy: 0.4501\n",
            "Epoch 10/10\n",
            "442/442 [==============================] - 142s 321ms/step - loss: 1.4595 - accuracy: 0.4209 - val_loss: 1.3105 - val_accuracy: 0.4912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model_swish loss and accuracy metrics using the evaluate_generator method and the test generator\n",
        "test_loss, test_acc = model_swish.evaluate(validation_generator, verbose=2)\n",
        "\n",
        "# Display the model's loss and accuracy results\n",
        "print(f\"Model_swish Loss: {test_loss}, Model_swish Accuracy: {test_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "j15n4Iew83bZ",
        "outputId": "3b0ed120-e3b8-4840-ef98-971bbe74678c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-5f9a0deddb60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate the model_swish loss and accuracy metrics using the evaluate_generator method and the test generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_swish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Display the model's loss and accuracy results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model_swish Loss: {test_loss}, Model_swish Accuracy: {test_acc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'evaluate'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model_adam_swish = ADAM Optimizer, Swish Activation\n",
        "\n",
        "model_adam_swish = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='swish', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='swish'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='swish'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='swish'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='swish'),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "model_adam_swish.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics = ['accuracy'])\n",
        "model_adam_swish.summary()\n",
        "# keras.utils.plot_model(model_adam_swish)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PT9xJ9xe83Xo",
        "outputId": "39247f13-d1f7-4961-a98a-25263ece6eb8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 148, 148, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 74, 74, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 72, 72, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 36, 36, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 34, 34, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 17, 17, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 15, 15, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 3136)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 512)               1606144   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 6)                 3078      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,669,734\n",
            "Trainable params: 1,669,734\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model_adam_swish\n",
        "model_adam_swish = model_adam_swish.fit(train_generator, \n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_generator,\n",
        "                    callbacks=early_stopping_cb)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "oLzHrWVF83Tp",
        "outputId": "76504527-4015-4a73-8e94-c7f5e4a0dab3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "442/442 [==============================] - 144s 325ms/step - loss: 1.7365 - accuracy: 0.2569 - val_loss: 1.6685 - val_accuracy: 0.3194\n",
            "Epoch 2/10\n",
            "442/442 [==============================] - 144s 325ms/step - loss: 1.7088 - accuracy: 0.2782 - val_loss: 1.7170 - val_accuracy: 0.2918\n",
            "Epoch 3/10\n",
            "442/442 [==============================] - 144s 327ms/step - loss: 1.6835 - accuracy: 0.2966 - val_loss: 1.5616 - val_accuracy: 0.3692\n",
            "Epoch 4/10\n",
            "442/442 [==============================] - 144s 325ms/step - loss: 1.6374 - accuracy: 0.3259 - val_loss: 1.4957 - val_accuracy: 0.4060\n",
            "Epoch 5/10\n",
            "402/442 [==========================>...] - ETA: 12s - loss: 1.6127 - accuracy: 0.3433"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-5dc0342f01ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     callbacks=early_stopping_cb)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model_adam_swish loss and accuracy metrics using the evaluate_generator method and the test generator\n",
        "\n",
        "test_loss, test_acc = model_adam_swish.evaluate(validation_generator, verbose=2)\n",
        "print(f\"Model_adam_swish Loss: {test_loss}, Model_adam_swish Accuracy: {test_acc}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "TDKPez62Ab34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xhs35HpkAb0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_cnn_lstm = cnn + lstm **model** "
      ],
      "metadata": {
        "id": "P3WQiNTRImqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model_cnn_lstm = cnn + lstm model\n",
        "# cnn model for feature extraction\n",
        "# lstm model for sequence classification\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.layers import Input\n",
        "from keras.layers import TimeDistributed\n",
        "\n",
        "# define cnn model\n",
        "def define_cnn_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(150, 150, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(128, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "    opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# define lstm model\n",
        "def define_lstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(150, 150, 3)))\n",
        "    model.add(LSTM(100, activation='relu'))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(6, activation='softmax'))\n",
        "  \n",
        "    # compile model\n",
        "    opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# define the hybrid model\n",
        "def define_hybrid_model():\n",
        "    # define CNN model\n",
        "    cnn_model = define_cnn_model()\n",
        "    # define LSTM model\n",
        "    lstm_model = define_lstm_model()\n",
        "    # define hybrid model\n",
        "    model = Sequential()\n",
        "    model.add(TimeDistributed(cnn_model, input_shape=(150, 150, 3)))\n",
        "    model.add(TimeDistributed(lstm_model))\n",
        "    # compile model\n",
        "    opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "Model_cnn_lstm = define_hybrid_model()\n",
        "Model_cnn_lstm.summary()\n",
        "\n",
        "#print(model.output_shape )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "27VdmC2LAbuv",
        "outputId": "2a3b2243-6b7a-476f-9d74-83e186cfd6ac"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-6752211bd222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mModel_cnn_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_hybrid_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0mModel_cnn_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-6752211bd222>\u001b[0m in \u001b[0;36mdefine_hybrid_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mcnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_cnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# define LSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mlstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_lstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;31m# define hybrid model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-6752211bd222>\u001b[0m in \u001b[0;36mdefine_lstm_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefine_lstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    212\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\u001b[0m\u001b[1;32m    215\u001b[0m                          \u001b[0;34m'is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                          \u001b[0;34mf'expected ndim={spec.ndim}, found ndim={ndim}. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 150, 150, 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model_cnn_lstm\n",
        " \n",
        "model_cnn_lstm= model_cnn_lstm.fit(train_generator,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_generator,\n",
        "                    callbacks=early_stopping_cb)\n"
      ],
      "metadata": {
        "id": "2_wyKiviAbrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model_cnn_lstm loss and accuracy metrics using the evaluate_generator method and the test generator\n",
        "\n",
        "test_loss, test_acc = model_cnn_lstm.evaluate(validation_generator, verbose=2)\n",
        "print(f\"Model_cnn_lstm Loss: {test_loss}, Model_cnn_lstm Accuracy: {test_acc}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "tHYfYHF_Abor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Loss function of models"
      ],
      "metadata": {
        "id": "DfiYpkM0wNBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss function for all the models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(model.history.history['loss'], label='train')\n",
        "plt.plot(model_adam.history.history['loss'])\n",
        "plt.plot(model_swish.history.history['loss'])\n",
        "plt.plot(model_adam_swish.history.history['loss'])\n",
        "plt.plot(model_cnn_lstm.history.history['loss'])\n",
        "\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['model = (RMS Optimizer, Relu Activation)',\n",
        "            'model_adam = ADAM optimizer, Relu Activation',\n",
        "            'model_swish = RMS Optimizer, Swish Activation',\n",
        "            'model_adam_swish = ADAM Optimizer, Swish Activation',\n",
        "            'model_cnn_lstm = CNN + LSTM '],\n",
        "            loc='upper left')\n",
        "\n"
      ],
      "metadata": {
        "id": "I-WWv8DOAbjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Accuracy function of models"
      ],
      "metadata": {
        "id": "IqXQmfyIxUz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the accuracy function for all the models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(model.history.history['accuracy'], label='train')\n",
        "plt.plot(model_adam.history.history['accuracy'])\n",
        "plt.plot(model_swish.history.history['accuracy'])\n",
        "plt.plot(model_adam_swish.history.history['accuracy'])\n",
        "plt.plot(model_cnn_lstm.history.history['accuracy'])\n",
        "\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['model = (RMS Optimizer, Relu Activation)',\n",
        "            'model_adam = ADAM optimizer, Relu Activation',\n",
        "            'model_swish = RMS Optimizer, Swish Activation',\n",
        "            'model_adam_swish = ADAM Optimizer, Swish Activation',\n",
        "            'model_cnn_lstm = CNN + LSTM '],\n",
        "            loc='upper left')\n"
      ],
      "metadata": {
        "id": "dihLvMMXmFGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrix"
      ],
      "metadata": {
        "id": "Q7YYMThUx5yL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "# model_adam\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "    \n",
        "y_pred = model_adam.predict(validation_generator)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(validation_generator.classes, y_pred))\n",
        "cm = confusion_matrix(validation_generator.classes, y_pred)\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        " "
      ],
      "metadata": {
        "id": "GTvx3hEgNKIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "# model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "    \n",
        "y_pred = model.predict(validation_generator)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(validation_generator.classes, y_pred))\n",
        "cm = confusion_matrix(validation_generator.classes, y_pred)\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        " \n"
      ],
      "metadata": {
        "id": "MEm0rN0kNJxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "# model_swish\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "    \n",
        "y_pred = model_swish.predict(validation_generator)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(validation_generator.classes, y_pred))\n",
        "cm = confusion_matrix(validation_generator.classes, y_pred)\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        " \n"
      ],
      "metadata": {
        "id": "HNdkRMCkwqnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "# model_adam_swish\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "    \n",
        "y_pred = model_adam_swish.predict(validation_generator)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(validation_generator.classes, y_pred))\n",
        "cm = confusion_matrix(validation_generator.classes, y_pred)\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        " "
      ],
      "metadata": {
        "id": "d0kYWh35w3s7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-ySWHM9tw3Qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot accuracy and loss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# accuracy\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b--', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# loss\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r--', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "0pqqm_-mBQyv",
        "outputId": "275357ef-0d86-4b19-e612-08cbd3920512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('model_weights.h5')"
      ],
      "metadata": {
        "id": "60zTf666F9o4"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_json=model.to_json()\n",
        "with open('model_json.json', 'w') as f: \n",
        "  f.write(model_json)"
      ],
      "metadata": {
        "id": "zgkY-LHeG0Q-"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_generator.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mI_3OMrHAOk",
        "outputId": "0dc7b12a-02ed-47dd-e546-19d95fa2ffb0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Angry': 0, 'Fear': 1, 'Happy': 2, 'Neutral': 3, 'Sad': 4, 'Suprise': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xPxF6UraIy0_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}